{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>month_interaction_count</th>\n",
       "      <th>week_interaction_count</th>\n",
       "      <th>day_interaction_count</th>\n",
       "      <th>cancelled_within_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  month_interaction_count  week_interaction_count   \n",
       "0         0                       43                       7  \\\n",
       "1         1                       41                      10   \n",
       "2         2                       43                      14   \n",
       "3         3                       34                       8   \n",
       "4         4                       46                       8   \n",
       "..      ...                      ...                     ...   \n",
       "95       95                       47                       6   \n",
       "96       96                       29                       6   \n",
       "97       97                       37                       8   \n",
       "98       98                       41                      10   \n",
       "99       99                       47                      14   \n",
       "\n",
       "    day_interaction_count  cancelled_within_week  \n",
       "0                       1                      0  \n",
       "1                       2                      1  \n",
       "2                       2                      1  \n",
       "3                       1                      1  \n",
       "4                       2                      1  \n",
       "..                    ...                    ...  \n",
       "95                      2                      0  \n",
       "96                      3                      1  \n",
       "97                      0                      1  \n",
       "98                      3                      1  \n",
       "99                      0                      0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Generate data\n",
    "n = 100\n",
    "data = {\n",
    "    'user_id': [x for x in range(0, n)],\n",
    "    'month_interaction_count': [random.randrange(25, 50) for x in range(0, n)],\n",
    "    'week_interaction_count': [random.randrange(6, 15) for x in range(0, n)],\n",
    "    'day_interaction_count': [random.randrange(0, 4) for x in range(0, n)],\n",
    "    \n",
    "    'cancelled_within_week': [random.randrange(0, 1+1) for x in range(0, n)],\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df#.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get features column\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Get label column \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorAssembler\n\u001b[1;32m----> 4\u001b[0m assembler \u001b[39m=\u001b[39m VectorAssembler(\n\u001b[0;32m      5\u001b[0m     inputCols\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mmonth_interaction_count\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mweek_interaction_count\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mday_interaction_count\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      6\u001b[0m     outputCol\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m df \u001b[39m=\u001b[39m assembler\u001b[39m.\u001b[39mtransform(df)\n\u001b[0;32m     10\u001b[0m df\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMethod \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m forces keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_kwargs \u001b[39m=\u001b[39m kwargs\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\feature.py:5358\u001b[0m, in \u001b[0;36mVectorAssembler.__init__\u001b[1;34m(self, inputCols, outputCol, handleInvalid)\u001b[0m\n\u001b[0;32m   5354\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5355\u001b[0m \u001b[39m__init__(self, \\\\*, inputCols=None, outputCol=None, handleInvalid=\"error\")\u001b[39;00m\n\u001b[0;32m   5356\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5357\u001b[0m \u001b[39msuper\u001b[39m(VectorAssembler, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m-> 5358\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_java_obj(\u001b[39m\"\u001b[39;49m\u001b[39morg.apache.spark.ml.feature.VectorAssembler\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muid)\n\u001b[0;32m   5359\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setDefault(handleInvalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5360\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_kwargs\n",
      "File \u001b[1;32mc:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:80\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[1;34m(java_class, *args)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[39mReturns a new Java object.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n\u001b[1;32m---> 80\u001b[0m \u001b[39massert\u001b[39;00m sc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     82\u001b[0m java_obj \u001b[39m=\u001b[39m _jvm()\n\u001b[0;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m java_class\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Get features column\n",
    "# Get label column \n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"month_interaction_count\", \"week_interaction_count\", \"day_interaction_count\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df = assembler.transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluation\u001b[39;00m \u001b[39mimport\u001b[39;00m BinaryClassificationEvaluator\n\u001b[0;32m      6\u001b[0m \u001b[39m# choose model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m lr \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[0;32m      9\u001b[0m \u001b[39m# make a grid search for all the parameters\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m### regularization\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m### threshold\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m### maxIter - tries 1 value\u001b[39;00m\n\u001b[0;32m     13\u001b[0m paramGrid \u001b[39m=\u001b[39m ParamGridBuilder()\u001b[39m.\u001b[39maddGrid(lr\u001b[39m.\u001b[39mregParam, [\u001b[39m0.1\u001b[39m, \u001b[39m0.01\u001b[39m])\\\n\u001b[0;32m     14\u001b[0m     \u001b[39m.\u001b[39maddGrid(lr\u001b[39m.\u001b[39melasticNetParam, [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1.0\u001b[39m])\\\n\u001b[0;32m     15\u001b[0m     \u001b[39m.\u001b[39maddGrid(lr\u001b[39m.\u001b[39mthreshold, [\u001b[39m0.4\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.6\u001b[39m])\\\n\u001b[0;32m     16\u001b[0m     \u001b[39m.\u001b[39maddGrid(lr\u001b[39m.\u001b[39mmaxIter, [\u001b[39m10\u001b[39m])\\\n\u001b[0;32m     17\u001b[0m     \u001b[39m.\u001b[39mbuild()\n",
      "File \u001b[1;32mc:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMethod \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m forces keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_kwargs \u001b[39m=\u001b[39m kwargs\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\classification.py:1318\u001b[0m, in \u001b[0;36mLogisticRegression.__init__\u001b[1;34m(self, featuresCol, labelCol, predictionCol, maxIter, regParam, elasticNetParam, tol, fitIntercept, threshold, thresholds, probabilityCol, rawPredictionCol, standardization, weightCol, aggregationDepth, family, lowerBoundsOnCoefficients, upperBoundsOnCoefficients, lowerBoundsOnIntercepts, upperBoundsOnIntercepts, maxBlockSizeInMB)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[39m__init__(self, \\\\*, featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", \\\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39m         maxIter=100, regParam=0.0, elasticNetParam=0.0, tol=1e-6, fitIntercept=True, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m \u001b[39mIf the threshold and thresholds Params are both set, they must be equivalent.\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m \u001b[39msuper\u001b[39m(LogisticRegression, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m-> 1318\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_java_obj(\n\u001b[0;32m   1319\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39morg.apache.spark.ml.classification.LogisticRegression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muid\n\u001b[0;32m   1320\u001b[0m )\n\u001b[0;32m   1321\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_kwargs\n\u001b[0;32m   1322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetParams(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Myles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:80\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[1;34m(java_class, *args)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[39mReturns a new Java object.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n\u001b[1;32m---> 80\u001b[0m \u001b[39massert\u001b[39;00m sc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     82\u001b[0m java_obj \u001b[39m=\u001b[39m _jvm()\n\u001b[0;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m java_class\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "# choose model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# make a grid search for all the parameters\n",
    "### regularization\n",
    "### threshold\n",
    "### maxIter - tries 1 value\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01])\\\n",
    "    .addGrid(lr.elasticNetParam, [0,0, 0.5, 1.0])\\\n",
    "    .addGrid(lr.threshold, [0.4, 0.5, 0.6])\\\n",
    "    .addGrid(lr.maxIter, [10])\\\n",
    "    .build()\n",
    "\n",
    "# Test the estimator (lr) and Splits data into 80/20 split\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=lr, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=BinaryClassificationEvaluator(), \n",
    "    trainRatio=.8\n",
    ")\n",
    "\n",
    "# Begins grid search\n",
    "model = tvs.fit(df)\n",
    "\n",
    "\n",
    "# Print results\n",
    "for x,y in zip(model.validationMetrics, model.getEstimatorParamMaps()):\n",
    "    for key, value in y.items():\n",
    "        print(key.name, value)\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"Accuracy: {x} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 iterations, 76% max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now: Use Bayesian Optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhyperopt\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n\u001b[0;32m      3\u001b[0m train_df, test_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mrandomSplit([\u001b[39m.8\u001b[39m, \u001b[39m.2\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(params):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "\n",
    "train_df, test_df = df.randomSplit([.8, .2])\n",
    "\n",
    "def train(params):\n",
    "    regParam = float(params['regParam'])\n",
    "    elasticNetParam = float(params['elasticNetParam'])\n",
    "    threshold = float(params['threshold'])\n",
    "    \n",
    "    lr = LogisticRegression(\n",
    "        maxIter=10,\n",
    "        regParam=regParam,\n",
    "        elasticNetParam=elasticNetParam,\n",
    "        threshold=threshold\n",
    "    )\n",
    "\n",
    "    lrmodel = lr.fit(train_df)\n",
    "    testEvaluation = lrmodel.evaluate(test_df)\n",
    "    print(\"Accuracy:\", testEvaluation.accuracy, \"Hyperparameters\", params)\n",
    "    return {'loss': -testEvaluation.accuracy, 'status': STATUS_OK} # return negative so we can minimize the loss function\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    'elasticNetParam': hp.uniform('elasticNetParam', 0, 1), # distribution between 0-1\n",
    "    'regParam': hp.uniform('regParam', .01, .1), \n",
    "    'threshold': hp.uniform('threshold', .4, .6), \n",
    "}\n",
    "\n",
    "algo = tpe.suggest # Tree of Parzen Estimators (Bayesian Method!)\n",
    "\n",
    "best_hyperparameters = fmin( #fmin() = \"Function to minimize\"\n",
    "    fn=train, # Function user-defined\n",
    "    space=search_space,\n",
    "    algo=algo,\n",
    "    max_evals=9 # note: earlier we had 18, only going to give them 9 this time!\n",
    ")\n",
    "\n",
    "print(\"Best hyperparameters:\", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 iterations, 85% max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
